{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f421c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial: https://towardsdatascience.com/real-time-face-recognition-an-end-to-end-project-b738bb0f7348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1363f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env vars loaded.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "from datetime import datetime\n",
    "# use this Python library to load your variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "print(\"Env vars loaded.\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fafe0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.6.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06098ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for user: \n"
     ]
    }
   ],
   "source": [
    "!sudo modprobe bcm2835-v4l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bdef7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_camera():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "    while(True):\n",
    "        ret, frame = cap.read()\n",
    "        #frame = cv2.flip(frame, -1) # Flip camera vertically\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.imshow('gray', gray)\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "test_camera()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22308452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_vid():\n",
    "    # https://github.com/Mjrovai/OpenCV-Face-Recognition/blob/master/FaceDetection/faceDetection.py\n",
    "    '''\n",
    "    Haar Cascade Face detection with OpenCV  \n",
    "        Based on tutorial by pythonprogramming.net\n",
    "        Visit original post: https://pythonprogramming.net/haar-cascade-face-eye-detection-python-opencv-tutorial/  \n",
    "    Adapted by Marcelo Rovai - MJRoBot.org @ 7Feb2018 \n",
    "    '''\n",
    "\n",
    "    # multiple cascades: https://github.com/Itseez/opencv/tree/master/data/haarcascades\n",
    "    faceCascade = cv2.CascadeClassifier(path.join('cv2_Cascades'), 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3,640) # set Width\n",
    "    cap.set(4,480) # set Height\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        #img = cv2.flip(img, -1)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # faceCascade.detectMultiScale: detects faces in img.\n",
    "        # Params:\n",
    "        # @scaleFactor: from \"https://www.geeksforgeeks.org/face-detection-using-cascade-classifier-using-opencv-python/\": ScaleFactor determines the factor of increase in window size which initially starts at size “minSize”, and after testing all windows of that size, the window is scaled up by the “scaleFactor”, and the window size goes up to “maxSize”. If the “scaleFactor” is large, (e.g., 2.0), there will be fewer steps, so detection will be faster, but we may miss objects whose size is between two tested scales. (default scale factor is 1.3)\n",
    "        # @minNeighbors: from \"https://www.geeksforgeeks.org/face-detection-using-cascade-classifier-using-opencv-python/\": Higher the values of the “minNeighbors”, less will be the number of false positives, and less error will be in terms of false detection of faces. However, there is a chance of missing some unclear face traces as well.\n",
    "        # @minSize: min Dims of a rectangle to be considered as a face if classified so\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5, # specifies how many neighbors each candidate rectangle should have, to retain it. A higher number gives lower false positives.\n",
    "            minSize=(20, 20)\n",
    "        )\n",
    "\n",
    "        # draw rectangles on image components when containing face(s): \n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            # keep updating the real-time capture\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "        cv2.imshow('video',img)\n",
    "\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27: # press 'ESC' to quit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "capture_vid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gray-scale user photos dataset\n",
    "def create_gs_user_photos_ds():\n",
    "    \n",
    "    gs_ds_dir = path.join(\"imgs\", \"user_photos\", \"gs\")\n",
    "    \n",
    "    # remove previous ds if exists and create a new empty one.\n",
    "    try:\n",
    "        shutil.rmtree(gs_ds_dir)\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(gs_ds_dir)\n",
    "    \n",
    "    cam = cv2.VideoCapture(0)\n",
    "    cam.set(3, 640) # set video width\n",
    "    cam.set(4, 480) # set video height\n",
    "    face_detector = cv2.CascadeClassifier(path.join('cv2_Cascades'), 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    print(\"[INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "    # Initialize individual sampling face count\n",
    "    count = 0\n",
    "    while(True):\n",
    "        ret, img = cam.read()\n",
    "        img = cv2.flip(img, -1) # flip video image vertically\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "            count += 1\n",
    "            # Save the captured image into the datasets folder\n",
    "            cv2.imwrite(path.join(gs_ds_dir_path, \"{0}.jpg\".format(count)), gray[y:y+h,x:x+w])\n",
    "            cv2.imshow('image', img)\n",
    "        k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif count >= 30: # Take 30 face sample and stop video\n",
    "             break\n",
    "    # Do a bit of cleanup\n",
    "    print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return None\n",
    "\n",
    "create_gs_user_photos_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gray_user_photos_ds():\n",
    "    \n",
    "    photos_dir = path.join(\"imgs\", \"user_photos\")\n",
    "    gray_photos_dir = path.join(photos_dir, \"gray\")\n",
    "    \n",
    "    # remove previous conversion output and create a new empty one.\n",
    "    try:\n",
    "        shutil.rmtree(gray_photos_dir)\n",
    "    except:\n",
    "        pass\n",
    "    os.mkdir(gray_photos_dir)\n",
    "    \n",
    "    filenames = os.listdir(photos_dir)\n",
    "    i = 0\n",
    "    for filename in filenames:\n",
    "        \n",
    "        # take file with \"jpg\", \"jpeg\", \"png\" extension only\n",
    "        if filename.split(\".\")[-1].lower() not in [\"jpg\", \"jpeg\", \"png\"]\n",
    "            continue\n",
    "        \n",
    "        filepath = path.join(photos_dir, filenames)\n",
    "        \n",
    "        img = cv2.imread(filepath, 0)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(filepath, gray)\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    print(\"Converted {0} user photos to gray scale\".format(i))\n",
    "    \n",
    "create_gray_user_photos_ds()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
